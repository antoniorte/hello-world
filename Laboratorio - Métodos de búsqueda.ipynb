{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28086fca-2cdd-41ac-b7bf-bc1af9f759a2",
   "metadata": {},
   "source": [
    "# Laboratorio: Métodos de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19abc1-82f0-4f28-9493-468e4227c14f",
   "metadata": {},
   "source": [
    "En las clases anteriores creaste códigos para realizar búsquedas aleatorias (Simulated Annealing) y búsquedas dirigidas (Optimización Bayesiana). Estos métodos de búsqueda se utilizan para facilitar el proceso de optimización de funciones objetivos compleja y costosas de computar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038474ce-6e2f-4d45-895a-bb17f7c8871d",
   "metadata": {},
   "source": [
    "En este laboratorio usaremos el dataset de los diferentes tipos de iris, y sus longitudes y anchos de pétalos y sépalos. Utilizaremos un RandomForest para crear un modelo de clasificación y el métrico F1 para decidir cuál es el mejor modelo de acuerdo a lo que tenemos disponible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04956ea-14f4-419e-adf8-add3b81da443",
   "metadata": {},
   "source": [
    "1. Carga el dataset de Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aad912f2-1359-437e-af68-3c8cca8d1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "X, y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b97ad91-d82b-491c-ac5d-be6f872c5334",
   "metadata": {},
   "source": [
    "2. Importa el archivo `Bosque.py`.\n",
    "\n",
    "Este archivo contiene la función `RegresionBosque`, que recibe:\n",
    "- X: las características independientes\n",
    "- y: la variable de respuesta\n",
    "- árboles: cantidad total de árboles\n",
    "- profundidad de bosque: niveles de profundidad del bosque\n",
    "\n",
    "Su salida es:\n",
    "- modelo: El objeto con el modelo ajustado\n",
    "- f1: El métrico que califica qué tan bueno es el modelo que se ajustó.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "23f875f1-a72a-4a57-8355-16d6bb9fb33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Bosque\n",
    "modelo, f1 = Bosque.RegresionBosque(X, y, 10, 3)\n",
    "f1 #ejectividad del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac2825-33ac-4919-9ccb-8324701ce99f",
   "metadata": {},
   "source": [
    "### Actividad 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7221ae41-2d64-455b-9b9f-aae8fce6e593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9444444444444444,\n",
       " 0.9555555555555556,\n",
       " 0.9555555555555556,\n",
       " 0.9444444444444444,\n",
       " 0.9555555555555556]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=5\n",
    "n_arboles=np.random.randint(5, 51, n)\n",
    "profundidad=np.random.randint(2,11, n)\n",
    "\n",
    "lista_f1 = []\n",
    "for n_arb, prof in zip(n_arboles, profundidad) :\n",
    "    modelo, f1 = Bosque.RegresionBosque(X, y, n_arb, prof) #x\n",
    "    lista_f1.append(f1)\n",
    "lista_f1 #y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb265f-9ccf-4fb4-b8c0-8fe221ea534c",
   "metadata": {},
   "source": [
    "Inicializa un espacio con 5 muestras en nuestro dominio de variables independientes:\n",
    "- árboles: números enteros entre 5 y 50.\n",
    "- profundidad: números enteros entre 2 y 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7c396-af97-49a6-828e-c5d63c1b6999",
   "metadata": {},
   "source": [
    "Utiliza optimización Bayesiana para encontrar la combinación de árboles y profundidad que **maximice** el métrico F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1e563392-4509-4d70-9cb6-adca944d2406",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "n_arb_vec = n_arboles.reshape([-1, 1])\n",
    "prof_vec = profundidad.reshape([-1, 1])\n",
    "X_hiperparam = np.hstack((n_arb_vec, prof_vec))\n",
    "\n",
    "\n",
    "kernel=1.0*RBF(length_scale=1)\n",
    "gp=GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(X_hiperparam, lista_f1)\n",
    "\n",
    "x_arb = np.linspace(5, 50, 1000).reshape([-1, 1])\n",
    "x_prof = np.linspace(2, 10, 1000).reshape([-1, 1])\n",
    "x_h = np.hstack((x_arb, x_prof))\n",
    "y_pred, y_std = gp.predict(x_h, return_std=True)\n",
    "y_pred_low=y_pred-1.96*y_std\n",
    "y_pred_high=y_pred+1.96*y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b1f76e9-0eab-429f-9509-4f2c7ec17d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  2.        ],\n",
       "       [ 5.04504505,  2.00800801],\n",
       "       [ 5.09009009,  2.01601602],\n",
       "       ...,\n",
       "       [49.90990991,  9.98398398],\n",
       "       [49.95495495,  9.99199199],\n",
       "       [50.        , 10.        ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e4377da2-251b-4e3d-ab15-dfbdf465c43d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1000, 5]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m      2\u001b[0m     kernel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\u001b[38;5;241m*\u001b[39mRBF(length_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     gp\u001b[38;5;241m=\u001b[39mGaussianProcessRegressor(kernel\u001b[38;5;241m=\u001b[39mkernel, n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(x_h, lista_f1)\n\u001b[0;32m      4\u001b[0m     x_arb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m     x_prof \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m1000\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape([\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:251\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    250\u001b[0m     dtype, ensure_2d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    252\u001b[0m     X,\n\u001b[0;32m    253\u001b[0m     y,\n\u001b[0;32m    254\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    255\u001b[0m     y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    256\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m    257\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m    258\u001b[0m )\n\u001b[0;32m    260\u001b[0m n_targets_seen \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m n_targets_seen \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_targets:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1281\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1263\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1264\u001b[0m     X,\n\u001b[0;32m   1265\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1277\u001b[0m )\n\u001b[0;32m   1279\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m-> 1281\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1000, 5]"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    kernel=1.0*RBF(length_scale=1)\n",
    "    gp=GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10).fit(x_h, lista_f1)\n",
    "    x_arb = np.linspace(5, 50, 1000).reshape([-1, 1])\n",
    "    x_prof = np.linspace(2, 10, 1000).reshape([-1, 1])\n",
    "    y_pred, y_std = gp.predict(x_h, return_std=True)\n",
    "    y_pred_low=y_pred-1.96*y_std\n",
    "    y_pred_high=y_pred+1.96*y_std\n",
    "    i_next=np.argmax(y_pred_high-y_pred_low)\n",
    "    X=np.vstack((X, x[i_next]))\n",
    "    Y=np.vstack((Y, f(x[i_next]))) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e083a3c-fa68-4942-b5d3-f1f7130b4fbb",
   "metadata": {},
   "source": [
    "### Actividad 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2817a47c-0081-4376-b222-c65735f4ab9d",
   "metadata": {},
   "source": [
    "Inicializa 2 vectores con posibles valores para las variables independientes:\n",
    "- árboles: números enteros entre 5 y 50\n",
    "- profundidad: números enteros entre 2 y 10\n",
    "\n",
    "Utiliza el algoritmo de Simulated Annealing que siga el siguiente orden:\n",
    "- Elige un punto de partida para las variables.\n",
    "- Selecciona al azar una de las dos para modificarlas.\n",
    "- Selecciona un elemento al azar de la lista que contiene los posibles valores de esa variable.\n",
    "- Sigue el algoritmo ($p$ y $q$) para decidir si usas esa combinación nueva o si mantienes la anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6286fe8-ec56-4871-9c31-8d4d3ca4c0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fa243-bd6d-4ec4-860a-2eae65cea710",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00442559-60d2-440a-9ba0-5217ea775ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
